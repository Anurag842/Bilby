{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de9e0a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 22:50:04,239 - INFO - Snowflake Connector for Python Version: 3.12.1, Python Version: 3.9.7, Platform: Windows-10-10.0.22631-SP0\n",
      "2024-08-22 22:50:04,244 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2024-08-22 22:50:04,245 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2024-08-22 22:50:04,855 - INFO - Number of results in first chunk: 1\n",
      "2024-08-22 22:50:05,271 - INFO - Number of results in first chunk: 1\n",
      "2024-08-22 22:50:05,272 - INFO - Article data inserted into Snowflake successfully!\n",
      "2024-08-22 22:50:05,272 - INFO - closed\n",
      "2024-08-22 22:50:05,324 - INFO - No async queries seem to be running, deleting session\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import locale\n",
    "import snowflake.connector\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Indonesian date handling\n",
    "locale.setlocale(locale.LC_TIME, 'id_ID.utf8')\n",
    "\n",
    "def fetch_article_data(url):\n",
    "  \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status() \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        title = soup.find('h1', class_='f50 black2 f400 crimson').text.strip()\n",
    "        \n",
    "        body = ' '.join([p.text for p in soup.find('div', class_='fl pt20 pos_rel').find_all('p')])\n",
    "\n",
    "        author = soup.find('div', class_='f20 credit mt10').text.strip()\n",
    "        author_extracted = (author[(author.find(':')+1):(author.find('Editor:'))].strip()).replace(\"\\n\", \"\").strip()\n",
    "        \n",
    "        #Stripping and converting the date\n",
    "        date = soup.find('div', class_='grey bdr3 pb10 pt10').text.strip()\n",
    "        date_str = date.replace(\"Tayang: \", \"\").split(\" WIB\")[0]\n",
    "        date_format = \"%A, %d %B %Y %H:%M\" \n",
    "        date_obj = datetime.strptime(date_str, date_format)\n",
    "\n",
    "        return title, body, author_extracted, date_obj\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error fetching the URL: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error parsing the article data: {e}\")\n",
    "        raise\n",
    "\n",
    "def snowflake_dump(title, body, author, date):\n",
    "   \n",
    "    try:\n",
    "        #snowflake connection details\n",
    "        conn = snowflake.connector.connect(\n",
    "            user='anuragdummyproton3',\n",
    "            password='Anuragdummyproton3',\n",
    "            account='lk35165.ap-south-1',\n",
    "            warehouse='COMPUTE_WH',\n",
    "            database='BILBY',\n",
    "            schema='STAGING'\n",
    "        )\n",
    "\n",
    "\n",
    "        cur = conn.cursor()\n",
    "\n",
    "      \n",
    "        create_table_query = \"\"\"\n",
    "        CREATE OR REPLACE TABLE articles (\n",
    "            title STRING,\n",
    "            body STRING,\n",
    "            author STRING,\n",
    "            date TIMESTAMP\n",
    "        );\n",
    "        \"\"\"\n",
    "        cur.execute(create_table_query)\n",
    "\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO articles (title, body, author, date)\n",
    "        VALUES (%s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        cur.execute(insert_query, (title, body, author, date))\n",
    "\n",
    "        conn.commit()\n",
    "        logging.info(\"Article data inserted into Snowflake successfully!\")\n",
    "\n",
    "    except snowflake.connector.errors.DatabaseError as e:\n",
    "        logging.error(f\"Database error: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error inserting data into Snowflake: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "       \n",
    "        if cur:\n",
    "            cur.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "def main():\n",
    "\n",
    "    url = 'https://www.tribunnews.com/new-economy/2024/08/07/lewat-teknologi-dan-edukasi-gopay-mendukung-pemberantasan-judi-online-di-indonesia'\n",
    "    #Fetch the data\n",
    "    title, body, author, date = fetch_article_data(url)\n",
    "    #Insert the data\n",
    "    snowflake_dump(title, body, author, date)\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c58c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
